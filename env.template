# Jarvis LLM Proxy API Environment
# Non-sensitive runtime config is stored in the settings DB.
# To seed settings from env: python scripts/seed_settings.py --force

# ============================================================================
# BOOTSTRAP + SECRETS (REQUIRED)
# ============================================================================

# Settings service discovery
JARVIS_CONFIG_URL=
JARVIS_AUTH_APP_ID=
JARVIS_AUTH_APP_KEY=

# Logging (jarvis-logs)
JARVIS_APP_ID=llm-proxy
JARVIS_APP_KEY=

# Internal auth (sensitive)
MODEL_SERVICE_TOKEN=
LLM_PROXY_INTERNAL_TOKEN=
JARVIS_ADMIN_TOKEN=

# Data stores (sensitive)
DATABASE_URL=
REDIS_URL=

# Third-party credentials (sensitive)
HUGGINGFACE_HUB_TOKEN=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# ============================================================================
# LIBRARY-LEVEL ENV (KEPT IN ENV)
# ============================================================================

S3_FORCE_PATH_STYLE=false
LLAMA_METAL=false
LLAMA_LOG_LEVEL=

# ============================================================================
# SERVER PORTS (USED BY RUN SCRIPTS)
# ============================================================================

SERVER_HOST=0.0.0.0
SERVER_PORT=8000
MODEL_SERVICE_PORT=8008

# Optional override for model service URL if settings are empty
# MODEL_SERVICE_URL=http://127.0.0.1:8008
