# Transformers Backend Example Configuration
# Copy this to .env and modify as needed

# Backend Configuration
JARVIS_MODEL_BACKEND=TRANSFORMERS
JARVIS_LIGHTWEIGHT_MODEL_BACKEND=TRANSFORMERS

# Model Configuration
JARVIS_MODEL_NAME=microsoft/DialoGPT-medium
JARVIS_MODEL_CHAT_FORMAT=generic
JARVIS_MODEL_CONTEXT_WINDOW=4096

JARVIS_LIGHTWEIGHT_MODEL_NAME=microsoft/DialoGPT-small
JARVIS_LIGHTWEIGHT_MODEL_CHAT_FORMAT=generic
JARVIS_LIGHTWEIGHT_MODEL_CONTEXT_WINDOW=2048

# Device Configuration
# Options: auto, cuda, mps, cpu
JARVIS_DEVICE=auto

# Torch Data Type
# Options: auto, float16, float32, bfloat16
JARVIS_TORCH_DTYPE=auto

# Quantization (optional, requires bitsandbytes)
JARVIS_USE_QUANTIZATION=false
JARVIS_QUANTIZATION_TYPE=4bit

# Generation Parameters
JARVIS_MAX_TOKENS=2048
JARVIS_TOP_P=0.95
JARVIS_TOP_K=50
JARVIS_REPETITION_PENALTY=1.1
JARVIS_DO_SAMPLE=true

# Memory Optimization
JARVIS_USE_CACHE=true
JARVIS_TRUST_REMOTE_CODE=false

# Server Configuration
PORT=8000
HOST=0.0.0.0

# Cache Configuration
JARVIS_ENABLE_CONVERSATION_CACHE=true
JARVIS_CONVERSATION_CACHE_MAX_SIZE=100
JARVIS_CONVERSATION_CACHE_TTL=3600

# Debug Configuration
DEBUG=false
DEBUG_PORT=5678
